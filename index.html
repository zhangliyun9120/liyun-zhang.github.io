<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
    <!--meta data-->
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="keywords" content="Liyun Zhang, Homepage, Osaka University, Graduate School of Information Science and Technology">
    <meta name="description" content="Liyun Zhang's Homepage">
	<!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
	
    <link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
    <link rel="stylesheet" href="./css/style.css" />

    <style type="text/css">
	</style>
    <title>Liyun Zhang - Homepage</title>
	<link rel="shortcut icon" href="./people/ZLY/icon/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="./people/ZLY/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./people/ZLY/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./people/ZLY/icon/favicon-16x16.png">
    <link rel="manifest" href="./people/ZLY/icon/manifest.json">
    <link rel="mask-icon" href="./people/ZLY/icon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="theme-color" content="#ffffff">


    <script src="./scripts/scroll.js"></script>
</head>

<body>

    <!-- Navigation Bar -->
    <div class="navbar-container">
        <nav>
            <div>
                <ul>
                    <li><a onclick="scrollToSection('home')">
                        <div class="clickable-area">Home</div>
                    </a></li>
                    <li><a onclick="scrollToSection('biography')">
                        <div class="clickable-area">Biography</div>
                    </a></li>
                    <li><a onclick="scrollToSection('news')">
                        <div class="clickable-area">News</div>
                    </a></li>
                    <li><a onclick="scrollToSection('publication')">
                        <div class="clickable-area">Publication</div>
                    </a></li>
                    <li><a onclick="scrollToSection('teams')">
                        <div class="clickable-area">Teams</div>
                    </a></li>
                    <li><a onclick="scrollToSection('teaching & working')">
                        <div class="clickable-area">Teaching & Working</div>
                    </a></li>
                    <li><a onclick="scrollToSection('talks')">
                        <div class="clickable-area">Talks</div>
                    </a></li>
                    <li><a onclick="scrollToSection('service')">
                        <div class="clickable-area">Service</div>
                    </a></li>
                </ul>
            </div>
        </nav>
    </div>

    <!-- Overall layout control -->
    <div id="layout-content" style="margin-top: 25px">
        <!-- Figure, Name, Addree, Email, CV, etc. -->
        <table id="home" class="home">
            <tbody>
                <tr>
                    <td width="19%" valign="top" height="173">
                        <img height="360" id="photo" style="padding: 10pt 30pt 0pt 10pt; float: left; display: inline;" src="./people/ZLY/zly.jpeg">
                    </td>
                    <td width="80%" valign="top" height="173">
                        <b><font face="Verdana" size="6">Liyun Zhang</font></b>
                        <br>
                        <br>
                        <p>
                            <b><font size="5">Ph.D. Candidate</font></b>
                        </p>
                        <p>
                            <a href="https://www.lab.ime.cmc.osaka-u.ac.jp/" target="_blank">Takemura Lab</a><br>
                            <a href="https://www.ist.osaka-u.ac.jp/" target="_blank">Graduate School of Information Science and Technology</a><br>
			    <a href="https://www.osaka-u.ac.jp/" target="_blank">Osaka University</a>
                            <br>
                            <br>
                            <strong>Address:</strong><br>
                            Cybermedia Center, Toyonaka Educational Research Center 5F 
                            <br>
                            Osaka University
                            <br>
                            1-32 Machikaneyama, Toyonaka, Osaka 560-0043, Japan
                            <br>
                            <br>
                            <strong>Email:</strong> liyun.zhang@lab.ime.cmc.osaka-u.ac.jp <br>
                            <br>
                            <a href="./CV.pdf" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/50x50/CV.png" class="inline-badge"/></a> &nbsp&nbsp&nbsp&nbsp 
		            <a href="https://scholar.google.co.jp/citations?view_op=list_works&hl=ja&authuser=2&hl=ja&user=zg9w4AMAAAAJ&authuser=2" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/50x50/Google.png" class="inline-badge"/></a> &nbsp&nbsp&nbsp&nbsp 
		            <a href="https://github.com/zhangliyun9120" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/50x50/github.png" class="inline-badge"/></a> &nbsp&nbsp&nbsp&nbsp 
			    <a href="https://space.bilibili.com/317616469?spm_id_from=333.999.0.0" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/50x50/bilibili.jpg" class="inline-badge"/></a> &nbsp&nbsp&nbsp&nbsp
		            <a href="https://www.linkedin.com/in/liyun-zhang-773733262/" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/50x50/In.png" class="inline-badge"/></a>
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>

        <!-- Biography -->
        <h2 id="biography">Biography</h2>
        <p style="text-align: justify; line-height: 1.5;">
            I am currently a Ph.D. candidate (will graduate in 2024.3) at <a href="https://www.lab.ime.cmc.osaka-u.ac.jp/" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/20x20/Lab.jpg" class="inline-badge"/>&nbsp;Takemura</span> Lab</a>, <a href="https://www.osaka-u.ac.jp/" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/30x30/Osaka.jpg" class="inline-badge"/>&nbsp;Osaka</span> University</a>, advised by  Prof. <a href="https://researchmap.jp/read0089576" target="_blank ">Haruo Takemura</a> and  Prof. <a href="https://researchmap.jp/photchara?lang=en" target="_blank">Photchara Ratsamee</a>. I am a visiting scholar at <a href="https://www.gatech.edu/" target="_blank" style="color:rgb(71, 146, 200)"><span class="no-break"><img src="./asset/30x30/gt.png" class="inline-badge"/>&nbsp;Georgia</span> Tech</a> advised by Prof. <a href="https://animesh.garg.tech/" target="_blank ">Animesh Garg</a> from 2023.2. I was a research intern at Sysmex Corporation, and worked at Huawei, ZTE Corporation, etc. 
        </p>
        <p style="text-align: justify; line-height: 1.5;">
            I'm interested in <strong>Multimodal Reasoning, Embodied AI, Interactive Robot Learning</strong> research fields.
        </p>
        <p style="text-align: justify; line-height: 1.5;">
            <strong style="color:red; font-size:120%;">Openings</strong>: I'm open to collaboration in research projects including "vision and language models used in robotics" and "robotic foundation models". <br>
            <span class="dot">&#8226;</span> I am looking for a research position at a university's or corporation's labs, including a postdoc, researcher and assistant professor, etc.
        </p>

        <!-- News -->
        <h2 id="news">News</h2>
        <div class="news-container">
            <div class="scrollable-content">
                <span class="dot">&#8226;</span> 2023.6: One paper about <a href="https://ieeexplore.ieee.org/document/10159430" target="_blank "> Vision Enhancement </a> accepted to TCSVT. <br>
                <span class="dot">&#8226;</span> 2023.2: I start a research collaboration with Georgia Tech advised by  Prof. <a href="https://animesh.garg.tech/" target="_blank ">Animesh Garg</a>. <br>
                <span class="dot">&#8226;</span> 2023.1: One paper about <a href="https://openaccess.thecvf.com/content/WACV2023/html/Zhang_Panoptic-Aware_Image-to-Image_Translation_WACV_2023_paper.html" target="_blank ">Image Translation</a></strong> accepted to <a href="https://wacv2023.thecvf.com/home" target="_blank ">WACV 2023</a>. <br>
                <span class="dot">&#8226;</span> 2022.11: One paper about <a href="https://ieeexplore.ieee.org/document/10018810" target="_blank ">Robotic Perception</a> accepted to <a href="https://ssrr2022.org/" target="_blank ">SSRR 2022</a>. <br>
            </div>
        </div>

        <!-- Publication -->
        <h2 id="publication">Publications</h2>
        # Corresponding author; * Equal contribution
        <table border="0" width="100%">
            <tbody>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Panoptic-Level Image-to-Image Translation for Object Recognition and Visual Odometry Enhancement -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/TCSVT2023/TCSVT2023.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Panoptic-Level Image-to-Image Translation for Object Recognition and Visual Odometry Enhancement</font>
                        <br>
			<strong>Liyun Zhang</strong>, Photchara Ratsamee, Zhaojie Luo, Yuki Uranishi, Manabu Higashida, Haruo Takemura. 
			<br>
			<em> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023.</em>
			<br>
                        <!-- [<a href="./projects/iPUNet/iPUNet.html" target="_blank">Project page</a>]&nbsp; -->
                        [<a href="./projects/TCSVT2023/TCSVT2023.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://segments.ai/panoptic/visible/" target="_blank">Code,Data</a>]&nbsp;
                        <!-- [<a href="https://doi.ieeecomputersociety.org/10.1109/TVCG.2023.3324924" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Panoptic-aware Image-to-Image Translation -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="260" style="padding: 0pt 10pt 0pt 0pt" src="./projects/WACV2023/WACV2023.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Panoptic-aware Image-to-Image Translation</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Photchara Ratsamee, Bowen Wang, Zhaojie Luo, Yuki Uranishi, Manabu Higashida, Haruo Takemura.
			<br>
			<em> IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023.</em>
			<br>
                        <!-- [<a href="https://arxiv.org/abs/2211.17048" target="_blank">arXiv</a>]
                        [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp; -->
                        [<a href="./projects/WACV2023/WACV2023.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/zhangliyun9120/PanopticGAN" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="https://www.computer.org/csdl/proceedings-article/wacv/2023/934600a259/1L6LxMYKoiQ" target="_blank">DOI</a>]<br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Thermal-to-Color Image Translation for Enhancing Visual Odometry of Thermal Vision -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/SSRR2022/SSRR2022.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Thermal-to-Color Image Translation for Enhancing Visual Odometry of Thermal Vision</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Photchara Ratsamee, Yuki Uranishi, Manabu Higashida, Haruo Takemura.
			<br>
			<em> IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR), 2022.</em>
			<br>
                        <!-- [<a href="https://arxiv.org/abs/2211.15502" target="_blank">arXiv</a>]
                        [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp; -->
                        [<a href="./projects/SSRR2022/SSRR2022.pdf" target="_blank">Paper</a>]&nbsp;
                        <!-- [<a href="" target="_blank">Code,Data (Comming soon...)</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Uneven Illumination Image Segmentation Based on Multi-threshold S-F -->
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/OEE2014/OEE2014.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Uneven Illumination Image Segmentation Based on Multi-threshold S-F</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Nanyan Liu, Yuanbin Hou, Xiaojian Liu.
			<br>
			<em> Opto-Electronic Engineering (OEE), 2014.</em>
			<br>
                        <!-- [<a href="https://ns.inria.fr/d3/cad2sketch/" target="_blank">Project page</a>]&nbsp; -->
                        [<a href="./projects/OEE2014/OEE2014.pdf" target="_blank">Paper</a>]&nbsp;
                        <!-- [<a href="https://gitlab.inria.fr/D3/cad2sketch" target="_blank">Code</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3550454.3555488" target="_blank">DOI</a>]<br> -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Free2CAD: Parsing Freehand Drawings into CAD Commands
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/free2cad/free2cad_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Free2CAD: Parsing Freehand Drawings into CAD Commands</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Hao Pan, Adrien Bousseau, Niloy Mitra. &nbsp;<em>ACM Transaction on Graphics, 41(4), 2022, proceedings of SIGGRAPH 2022. </em><br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2022/free2cad/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/free2cad/Free2CAD_SIG_2022.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/Free2CAD" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/free2cad/Free2CAD_supl.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3528223.3530133" target="_blank">DOI</a>]<br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;"><strong>Best Paper Honorable Mention Award</strong></a></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- VertNet: Accurate Vertebra Localization and Identification Network from CT Images
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/vertNet/vertNet_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">VertNet: Accurate Vertebra Localization and Identification Network from CT Images</font>
                        <br>
                        Zhiming Cui, <strong>Liyun Zhang</strong>, Lei Yang, Chunfeng Lian, Feng Shi, Wenping Wang, Dijia Wu, Dinggang Shen. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2021. <br>
                        [<a href="./projects/vertNet/VertNet.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/vertNet/VertNet_MICCAI_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation 
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/cardiactSeg/cardiacSeg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation</font>
                        <br>
                        Zhiming Cui, <strong>Liyun Zhang</strong>, Zhixu Du, Nenglun Chen, Guodong Wei, Runnan Chen, Lei Yang, Wenping Wang. IEEE Transactions on Medical Imaging (TMI), 2021. <br>
                        [<a href="./projects/cardiactSeg/cardiacSeg.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/cardiactSeg/src/CardiacSeg_DomainAdaptation_TMI_2021.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks 
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/scaffoldGAN/scaffoldGAN_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks</font>
                        <br>
                        Hui Zhang, Lei Yang, <strong>Liyun Zhang</strong>, Bojian Wu, Wenping Wang. Computer-Aided Design (CAD), 2021. <br>
                        [<a href="./projects/scaffoldGAN/ScaffoldGAN_CAD_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Hierarchical Morphology-Guided Tooth Instance Segmentation from CBCT Images 
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/skeleToothSeg/skeleToothSeg_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Hierarchical Morphology-Guided Tooth Instance Segmentation from CBCT Images</font>
                        <br>
                        Zhiming Cui<sup>*</sup>, Bojun Zhang<sup>*</sup>, Chunfeng Lian, <strong>Liyun Zhang<sup>#</sup></strong>, Lei Yang, Min Zhu<sup>#</sup>, Wenping Wang, Dinggang Shen<sup>#</sup>. Information Processing in Medical Imaging (IPMI), 2021. <br>
                        [<a href="./projects/skeleToothSeg/skele_tseg.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="./projects/skeleToothSeg/src/ToothSeg_IMPI_2021.pdf" target="_blank">Paper</a>]&nbsp;</br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><strong>Oral Presentation</strong></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Point2Skeleton: Learning Skeletal Representations from Point Clouds 
                <tr>
                    <td>
                        <div align="center">
                            <img width="270" style="padding: 0pt 10pt 0pt 0pt" src="./projects/point2skeleton/p2s_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Point2Skeleton: Learning Skeletal Representations from Point Clouds</font>
                        <br>
                        Cheng Lin, <strong>Liyun Zhang<sup>#</sup></strong>, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping Wang<sup>#</sup>. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021. <br>
                        [<a href="./projects/point2skeleton/point2skeleton.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Point2Skeleton_Learning_Skeletal_Representations_from_Point_Clouds_CVPR_2021_paper.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/clinplayer/Point2Skeleton" target="_blank">Code</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <em><strong>Oral Presentation, Best Paper Candidate</strong></em></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- TSegNet: an Efficient and Accurate Tooth Segmentation Network on 3D Dental Model
                <tr>
                    <td>
                        <div align="center">
                            <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/tsegNet/tseg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">TSegNet: an Efficient and Accurate Tooth Segmentation Network on 3D Dental Model</font>
                        <br>
                        Zhiming Cui, <strong>Liyun Zhang</strong>, Nenglun Chen, Guodong Wei, Runnan Chen, Yuanfeng Zhou, Dinggang Shen, Wenping Wang.&nbsp;<em> Medical Image Analysis (MIA) </em>, 2021<br>
                        [<a href="./projects/tsegNet/TSegNet.html" target="_blank">Project Page</a>]
                        [<a href="./projects/tsegNet/paper/TSegNet_MIA_2021.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="" target="_blank">Code</a>]
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- RigidFusion: RGB-D Scene Reconstruction with Rigidly-moving Objects 
                <tr>
                    <td>
                        <div align="center">
                            <img width="290" style="padding: 0pt 10pt 0pt 0pt" src="./projects/rigidFusion/rigidFusion_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">RigidFusion: RGB-D Scene Reconstruction with Rigidly-moving Objects</font>
                        <br>
                        Yushiang Wong, <strong>Liyun Zhang</strong>, Matthias Niessner, Niloy Mitra. &nbsp&nbsp&nbsp;<em> Eurographics (EG) </em>, 2021.<br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2021/rigidfusion/" target="_blank">Project Page</a>]&nbsp;
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2021/rigidfusion/paper_docs/rigidfusion_eg21.pdf" target="_blank">Paper</a>]&nbsp;
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform 
                <tr>
                    <td>
                        <div align="center">
                            <img height="120" style="padding: 0pt 10pt 0pt 0pt" src="./projects/segmat/segmat_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform</font>
                        <br>
                        Cheng Lin, Lingjie Liu, <strong>Liyun Zhang</strong>, Leif Kobbelt, Bin Wang, Shiqing Xin, Wenping Wang. &nbsp;<em> IEEE Visualization and Computer Graphics (TVCG)</em>, 2020<br>
                        [<a href="./projects/segmat/SEG-MAT.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/2010.11488" target="_blank">arXiv Preprint</a>]
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Sketch2CAD: Sequential CAD Modeling by Sketching in Context 
                <tr>
                    <td>
                        <div align="center">
                            <img width="250" style="padding: 0pt 10pt 0pt 0pt" src="./projects/sketch2cad/sketch2cad_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Sketch2CAD: Sequential CAD Modeling by Sketching in Context</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Hao Pan, Adrien Bousseau, Niloy Mitra. &nbsp;<em>ACM Trans. Graph., 39(6), 2020, proceedings of SIGGRAPH Asia 2020</em><br>
                        [<a href="http://geometry.cs.ucl.ac.uk/projects/2020/sketch2cad/" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/sketch2cad/Sketch2CAD_SIGA_2020.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/Sketch2CAD" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/sketch2cad/Sketch2CAD_supl.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://doi.org/10.1145/3414685.3417807" target="_blank">DOI</a>]<br>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Floorplan-Jigsaw: Jointly Estimating Scene Layout and Aligning Partial Scans 
                <tr>
                    <td>
                        <div align="center">
                            <img height="150" style="padding: 0pt 10pt 0pt 0pt" src="./projects/indoorRecons/indoor_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Floorplan-Jigsaw: Jointly Estimating Scene Layout and Aligning Partial Scans</font>
                        <br>
                        Cheng Lin, <strong>Liyun Zhang</strong>, Wenping Wang. &nbsp;<em> International Conference on Computer Vision (ICCV)</em>, 2019<br>
                        [<a href="./projects/indoorRecons/floorplanJigsaw.html" target="_blank">Project Page</a>]&nbsp;
                        [<a href="https://arxiv.org/abs/1812.06677" target="_blank">arXiv</a>]
                        [<a href="./projects/indoorRecons/src/paper/floorplanJigsaw_ICCV2019.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/indoorRecons/src/supl/floorplanJigsaw_ICCV2019_Supplemental_Material.pdf" target="_blank">Supl</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"><strong>Our poster session is highlighted in the 'Computer Vision News, The magazine of the algorithm community': <a href="https://www.rsipvision.com/ICCV2019-Friday/16/" target="_blank">ICCV Daily 2019, Friday</a></strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- ToothNet: Automatic Tooth Instance Segmentation and Identification from Cone Beam CT Images 
                <tr>
                    <td>
                        <div align="center">
                            <img height="150" style="padding: 0pt 10pt 0pt 0pt" src="./projects/toothSeg/toothSeg_icon.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">ToothNet: Automatic Tooth Instance Segmentation and Identification from Cone Beam CT Images</font>
                        <br>
                        Zhiming Cui, <strong>Liyun Zhang</strong>, Wenping Wang. &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. </strong></em><br>
                        [<a href="./projects/toothSeg/toothNet.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/toothSeg/paper/toothNet_CVPR2019.pdf" target="_blank">Paper</a>]&nbsp; </br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"> <strong>Our poster session is highlighted in the technical news of IEEE Computer Society: <a href="https://www.computer.org/publications/tech-news/events/ieee-conference-on-computer-vision-and-pattern-recognition-2019-poster-sessions" target="_blank">Poster Sessions Provoke Deep Discussions at the 2019 Conference on CVPR.</a> </strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling 
                <tr>
                    <td>
                        <div align="center">
                            <img height="170" style="padding: 0pt 10pt 0pt 0pt" src="./projects/sketchcnn/sketchcnn_icon2.png" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Hao Pan, Yang Liu, Xin Tong, Alla Sheffer, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 37(6), 2018, proceedings of SIGGRAPH Asia 2018</em><br>
                        [<a href="http://haopan.github.io/sketchCNN.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/sketchcnn/SketchCNN_SIGA_2018.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="https://github.com/Enigma-li/SketchCNN/" target="_blank">Code,Data</a>]&nbsp;
                        [<a href="./projects/sketchcnn/supplemental.pdf" target="_blank">Supl</a>]&nbsp;
                        [<a href="https://dl.acm.org/citation.cfm?id=3275051" target="_blank">DOI</a>]</br>
                        <p style="color:red;font-size:60%;">  </p>
                        <p style="color:red;font-size:100%;"><strong>Our Teaser image was selected as the <a href="./projects/sketchcnn/cover_image.png"><strong>cover image</strong></a> of Transaction on Graphics of year 2018. And it also was selected by ACM SIGGRAPH Asia for technical paper <a href="https://sa2018.siggraph.org/images/press-releases/SA18%20Tech%20Papers%20PR%20-%2030%20Nov%2018%20-%20Making%20It%20Easier%20To%20Transform%202D%20Sketching%20Into%203D%20Models.pdf"><strong>press release</strong></a> as research highlights. </strong></p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- BendSketch: Modeling Freeform Surfaces Through 2D Sketching 
                <tr>
                    <td>
                        <div align="center">
                            <img width="240" style="padding: 0pt 10pt 0pt 0pt" src="./projects/bendsketching/bendsketch_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">BendSketch: Modeling Freeform Surfaces Through 2D Sketching</font>
                        <br>
                        <strong>Liyun Zhang</strong>, Hao Pan, Yang Liu, Xin Tong, Alla Sheffer, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 36(4), 2017, proceedings of SIGGRAPH 2017</em><br>
                        [<a href="http://haopan.github.io/bendsketch.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/bendsketching/bendsketch.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/bendsketching/BendSketchData.zip" target="_blank">Data</a>]
                        <!-- [<a href="">DOI</a>] -->
                    </td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                </tr>
                <!-- Flow Aligned Surfacing of Curve Networks 
                <tr>
                    <td>
                        <div align="center">
                            <img width="200" style="padding: 0pt 10pt 0pt 0pt" src="./projects/curvnet_surfacing/curvenet_surfacing_icon.jpg" alt="">
                        </div>
                    </td>
                    <td>
                        <font style="line-height: 180%; font-weight: bold">Flow Aligned Surfacing of Curve Networks</font>
                        <br>
                        Hao Pan, Yang Liu, Alla Sheffer, Nicholas Vining, <strong>Liyun Zhang</strong>, Wenping Wang. &nbsp;<em>ACM Trans. Graph., 36(4), 2015, proceedings of SIGGRAPH 2015</em><br>
                        [<a href="http://haopan.github.io/curvenet_surfacing.html" target="_blank">Project page</a>]&nbsp;
                        [<a href="./projects/curvnet_surfacing/sketch_surface.pdf" target="_blank">Paper</a>]&nbsp;
                        [<a href="./projects/curvnet_surfacing/curve_surfacing_curves_meshes.zip" target="_blank">Data</a>]
                        <!-- [<a href="">DOI</a>] -->
                    </td>
                </tr>
            </tbody>
        </table>

        <!-- Team -->
        <h2 id="team">Teams</h2>
        <div class="table-container">
            <h3>Embodied Reasoning:</h3>
            <table class="content-table">
                <tbody>
                    <tr>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/animesh.jpg" alt=""> <br>
                            <a href="https://animesh.garg.tech/" target="_blank">Animesh Garg</a> <br> Assistant Professor <br>
                            (Georgia Tech)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/jason.PNG" alt=""> <br>
                            <a href="https://www.jeoresearch.com/" target="_blank">Jason Orlosky</a> <br> Associate Professor <br> (Augusta University & Osaka University)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/ratsamee.png" alt=""> <br>
                            <a href="https://researchmap.jp/photchara?lang=en" target="_blank">Photchara Ratsamee</a> <br> Lecturer <br> (Osaka Institute of Technology & Osaka University)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/kobayashi.jpg" alt=""> <br>
                            <a href="https://mertcookimg.github.io/" target="_blank">Masato Kobayashi</a>  <br> Assistant Professor <br>
                            (Osaka University)
                        </td>
                    </tr>
                    <tr>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/atharva.jpg" alt=""> <br>
                            Atharva Mete</a>  <br> Master <br>
                            (Georgia Tech)
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        <!-- 
        <div class="table-container">
            <h3>Visiting and Intern Students</h3>
            <table class="content-table">
                <tbody>
                    <tr>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/guangshun.jpg" alt=""> <br>
                            <a href="https://gsw-d.github.io/gswei.github.io/" target="_blank">Guangshun Wei</a> (Postdoc)<br>
                            (Visiting Researcher - remote)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/shuyuan.png" alt=""> <br>
                            Shuyuan Zhang (UG) <br>
                            (Intern Student)
                        </td>
                        <!-- <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/jiawei.jpg" alt=""> <br>
                            Jiawei Wang (UG) <br>
                            (Intern Student - remote)
                        </td>
                        <td style="text-align: center;">
                            <img class="roundImg" src="./people/Current/kuankuan.jpg" alt=""><br>
                            Kuankuan Cheng (UG)<br>(Intern Student - remote)
                        </td>
                        <td style="text-align: center;">
                            <!-- placeholder
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="table-container">
            <h3>Former Group Memembers</h3>
            <table id="tbTeaching" border="0" width="100%">
                <tbody>
                    <tr>
                        <td>Jing Xu, &nbsp;&nbsp; UG, Intern Student, 2023.09-2023.12</td>
                    </tr>
                    <tr>
                        <td>Jiawei Wang, &nbsp;&nbsp; UG, Intern Student (remote), 2023.04-2023.11</td>
                    </tr>
                </tbody>
            </table>
        </div> -->

        <!-- Teaching -->
        <h2 id="teaching">Teaching & Working</h2>
            <table id="tbTeaching" border="0" width="100%">
                <tbody>
                    <tr>
                        <td>2023.2-2024.3</td>
                        <td>Visiting Researcher</td>
                        <td>Georgia Tech</td>
                    </tr>
                    <tr>
                        <td>2023.7-2024.2</td>
                        <td>Research Assistant</td>
                        <td>Osaka University</td>
                    </tr>
                    <tr>
                        <td>2021.5-2023.3</td>
                        <td>Specially Appointed Researcher</td>
                        <td><a href="https://www.sysmex.co.jp/en/index.html" target="_blank">Sysmex Corporation</a></td>
                    </tr>
                    <tr>
                        <td>2021.4-2021.9</td>
                        <td>Teaching Assistant</td>
                        <td>Osaka University</td>
                    </tr>
                    <tr>
                        <td>2020.10-2021.3</td>
                        <td>Research Assistant</td>
                        <td>Osaka University</td>
                    </tr>
		    <tr>
                        <td>2017.12-2018.9</td>
                        <td>Senior Embedded Software Engineer</td>
                        <td><a href="https://www.zte.com.cn/global/index.html" target="_blank">ZTE Corporation</a></td>
                    </tr>
		    <tr>
                        <td>2016.11-2017.3</td>
                        <td>Software R&D Engineer</td>
                        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.huawei.com/en/" target="_blank">Huawei</a></td>
                    </tr>
		    <tr>
                        <td>2015.7-2017.12</td>
                        <td>Embedded Software Engineer</td>
                        <td><a href="https://en.huaqin.com/" target="_blank">Huaqin Technology</a></td>
                    </tr>
                </tbody>
            </table>

        <!-- Research Experience -->
        <!--
        <h2>Research Experiences</h2>
        <table id="tbExperiences" border="0" width="100%">
            <tbody>
                <tr>
					<td>Oct. 2021 - July 2022</td>
					<td>Starting Researcher</td>
					<td><a href="http://www-sop.inria.fr/members/Adrien.Bousseau/" target="_blank">Dr. Adrien Bousseau</a></td>
                </tr>
                <tr>
					<td>Oct. 2019 - Sept. 2021</td>
					<td>Postdoctoral Research Associate</td>
					<td><a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/index.html" target="_blank">Prof. Niloy Mitra</a></td>
                </tr>
                <tr>
					<td>Sept. 2018 - Jan. 2019</td>
					<td>Visiting Graduate Student, University of Toronto</td>
					<td><a href="http://www.cs.toronto.edu/~jacobson/" target="_blank">Prof. Alec Jacobson</a> and <a href="http://diwlevin.webfactional.com/researchdb/" target="_blank">Prof. David Levin</a></td>
                </tr>
                <tr>
					<td>Feb. 2016 &nbsp;- Aug. 2018</td>
					<td>Research Intern <em>(multiple times)</em>, Microsoft Research Asia</td>
					<td><a href="http://haopan.github.io/" target="_blank">Dr. Hao Pan</a> and <a href="https://xueyuhanlang.github.io/" target="_blank">Dr. Yang Liu</a></td>
                </tr>
                <tr>
					<td>Feb. 2014 &nbsp;- May 2014</td>
					<td>Research Assistant, The University of Hong Kong</td>
					<td><a href="http://i.cs.hku.hk/~wenping/" target="_blank">Prof. Wenping Wang</a> and <a href="http://haopan.github.io/" target="_blank">Dr. Hao Pan</a></td>
                </tr>
            </tbody>
        </table>
        -->
		
        <!-- Invited Talk -->
        <h2 id="talks">Invited Talks</h2>
        <table id="tbTalks" border="0" width="100%">
            <tbody>
                <tr>			
                    <td>In Progress</td>
                </tr>
                <!--<tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong> <a href="https://irc.cs.sdu.edu.cn/gdc2022/index.html#/ztlt" target="_blank">Invited workshop speaker at GDC</a>, Qingdao, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Free2CAD: Parsing Freehand Drawings into CAD Commands.</td>					
                    <td>Aug. 2022</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>School of Software, Tsinghua University, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Creating, Analyzing and Processing 3D Data: Applications to interactive 3D modeling and to medical imaging.</td>					
                    <td>Dec. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>School of Informatics, University of Edinburgh, UK</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Creating, Analyzing and Processing 3D Data: Applications to interactive 3D modeling and to medical imaging.</td>					
                    <td>Oct. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>Stanford Human-Computer Interaction group, Stanford</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch2CAD: Sequential CAD Modeling by Sketching in Context.</td>					
                    <td>Jan. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>AI Lab Sharing Session, Autodesk</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch2CAD: Sequential CAD Modeling by Sketching in Context.</td>					
                    <td>Jan. 2021</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>Software College, Shandong University, Jinan</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Sketch-based Freeform Surface Modeling.</td>					
                    <td>Oct. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>iDDA, The Chinese University of Hong Kong, Shenzhen</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;SketchAShape: Sketch-based Freeform Surface Modeling.</td>					
                    <td>Jul. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>IRC Lab, Shandong University</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling.<br>&nbsp;&nbsp;&nbsp;&nbsp;Automatic Tooth Instance Segmentation and Identification from CBCT Images.</td>					
                    <td>Mar. 2019</td>
                </tr>
                <tr>
                    <td>
                        <br>
                    </td>
                <tr>
                <tr>
                    <td><strong>DGP Lab, University of Toronto</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;BendSketch: Modeling Freeform Surfaces Through 2D Sketching.</td> 
                    <td>Sept. 2018</td>
                </tr>
                    <td>
                        <br>
                    </td>
                <tr>
                </tr>
                <tr>
                    <td><strong>GAMES: Graphics And Mixed Environment Seminar, China</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;Robust Flow-Guided Neural Prediction for Sketch-Based Freeform Surface Modeling.</td>
                    <td>Nov. 2018</td>
                </tr> -->
            </tbody>
        </table>
        
        <!-- Service: Committee, Reviewer, etc. -->
        <h2 id="service">Recent Community Services</h2>
        <!-- Program Committees -->
        <!-- <h3>Committee Service</h3>
        <table id="tbCommittees" border="0" width="100%">
            <tbody>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; SIGGRAPH Asia: Technical Program Committee 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; SIGGRAPH</td>
                </tr>
                <tr>
                    <td>&emsp;&emsp;&#8226; Poster Jury Committee, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;&#8226; Geometry Design and Computing (GDC): Technical Program Committee 2022, 2023 </td>
                </tr>
            </tbody>
        </table> -->
        
        <!-- Reviewer -->
        <h3>Reviewer Service</h3>
        <table id="tbReviewer" border="0" width="100%">
            <tbody>
                <tr>
                    <td>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>Conference on Computer Vision and Pattern Recognition (CVPR)</td>
                    <td>2022</td>
                </tr>
                <tr>
                    <td>European Conference on Computer Vision (ECCV)</td>
                    <td>2022</td>
                </tr>
                <!-- <tr>
                    <td>&nbsp;&nbsp;IEEE Transactions on Visualization & Computer Graphics (TVCG)</td>
                    <td>2020-2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Eurographics (EG)</td>
                    <td>2019-2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;ACM SIGCHI</td>
                    <td>2020, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp; ACM Symposium on User Interface Software and Technology (UIST)</td>
                    <td>2020</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Computer-Aided Design (CAD)</td>
                    <td>2019, 2022-2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Computer Graphics Forum (CGF)</td>
                    <td>2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Journal of Computer Science and Technology (JCST)</td>
                    <td>2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Pacific Graphics (PG)</td>
                    <td>2018, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Eurographics Symposium on Geometry Processing (SGP)</td>
                    <td>2018</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;International Conference on Computer-Aided Design and Computer Graphics (CAD&CG)</td>
                    <td>2015, 2019</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Geometry Design and Computing (GDC)</td>
                    <td>2022, 2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;IEEE Transactions on Image Processing (TIP)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Journal of Computer Science and Technology (JCST)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;The Visual Computer (TVCJ)</td>
                    <td>2023</td>
                </tr>
                <tr>
                    <td>&nbsp;&nbsp;Sensors</td>
                    <td>2020</td>
                </tr> -->
                
            </tbody>
        </table>

        <h4>
            <br>
            <div align="center">
                <b>&copy;Liyun Zhang.</b>&nbsp; Last update: February, 2024.
            </div
        </h4>
</body>
</html>
